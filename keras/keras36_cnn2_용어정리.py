# keras36_cnn2_용어정리.py

# https://keras.io/api/layers/convolution_layers/convolution2d/
# https://keras.io/api/layers/core_layers/dense/

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten

# (N, 5,5,3) 이미지 
# batch = 샘플 수
# 이미지가 4차원인 이유 : N(샘플)개의 갯수, 가로 5픽셀, 세로 5픽셀, RGB(1 또는 3) : 갯수+가로해상도+세로해상도+색상(채널) -> 4차원
# 반면, 데이터프레임 행렬연산은 2차원이다(샘플 수 x 컬럼). 행(데이터갯수)는 마찬가지로 차원에 포함되지 않는다. 
# 신경망모델 입력데이터는 연산이 가능한 형태로 reshape해야한다(시리즈나 넘파이배열 (5,) 을 연산하려면 (5,1)같은 2차원 형태로 reshape해야하고 이미지를 연산하려면 4차원으로 reshape해야한다.)
# 모델 중간에서는 값과 순서 유지하면서 차원축소 가능하다
model = Sequential()
                                                # height, width, channels
                                                # 가로, 세로, 색깔
model.add(Conv2D(filters=10, kernel_size=(2,2), input_shape=(5, 5, 3)))     # (None, 4, 4, 10) : 아웃풋 10 / 커널사이즈 2X2 / 5,5,3   // None -> batch크기가 정해지지 않았음
model.add(Conv2D(5, (2,2)))                                                 # (None, 3, 3, 5) : 아웃풋이 3x3해상도이며 5개(필터)를 생성했다
# model.add(Conv2D(3, (2,2)))                                               # (None, 2, 2, 3) : 아웃풋이 2x2해상도이며 3개(필터)를 생성했다
# 인풋레이어에서는 '채널' / 이후 레이어에서는 '필터'라고 부른다 / 커널=가중치
# kernel_size를 너무 줄이면 오히려 데이터가 손실된다.

# model.add(Dense(10))    # (None, 3, 3, 10) :입력이 4차원이라 4차원 출력

# 2차원을 출력하고싶으면 reshape를 해야한다.(y가 2차원이라서)
# (16,) = (4, 4) = (4, 2, 2) = (4, 2, 2, 1) : 값과 순서만 같으면 된다.

# reshape : 4차원을 flatten해서 2차원으로 변환
model.add(Flatten())        # (None, 45) <- 3x3x5=45 : 전 레이어의 아웃풋개수(가로x세로x필터)만큼을 평평하게펴서 다음 레이어에 전달. reshape이기때문에 연산하지 않는다(Param 0)
model.add(Dense(units=10))  # (None, 10) / units : 아웃풋 노드의 갯수
model.add(Dense(3))         # 마지막레이어는 사람이 인식하는 형태로 변형하기위해 Dense로 변환한다.

model.summary()
# Model: "sequential"
# _________________________________________________________________
#  Layer (type)                Output Shape              Param #
# =================================================================
#  conv2d (Conv2D)             (None, 4, 4, 10)          130

#  conv2d_1 (Conv2D)           (None, 3, 3, 5)           205

#  flatten (Flatten)           (None, 45)                0

#  dense (Dense)               (None, 10)                460

#  dense_1 (Dense)             (None, 3)                 33

# =================================================================
# Total params: 828
# Trainable params: 828
# Non-trainable params: 0
# _________________________________________________________________
# 첫번째 레이어 Output Shape에서 채널이 10이 나오는 이유? 출력을 10으로 했기때문에 4x4이미지가 10개로 증폭되어 다음 레이어로 전달
# Param : 가중치 + 편향 갯수
# CNN의 weight는 커널사이즈이다 -> 커널이 클수록 연산량이 늘어난다.

"""
    [1. 커널(필터) 크기가 클 때]
        (장점)
        넓은 영역의 특징 포착: 한 번의 연산으로 더 넓은 영역(더 많은 픽셀)의 정보를 한꺼번에 볼 수 있어, 이미지의 전역적 패턴이나 큰 구조를 빠르게 학습할 수 있습니다.
        적은 레이어로 넓은 수용영역: 커널이 크면 적은 층만 쌓아도 입력 전체에 가까운 정보를 포착할 수 있습니다.

        (단점)
        파라미터 수 증가: 커널이 커질수록 각 필터의 학습 파라미터(가중치) 수가 증가해, 전체 모델의 파라미터가 많아집니다.
        연산량 증가: 커널이 크면 계산량이 많아져 학습 속도가 느려지고, 메모리 사용량도 늘어납니다.
        세밀한 특징 추출 한계: 큰 커널은 미세한(local) 특징이나 경계선, 작은 패턴을 놓칠 수 있습니다.

    [2. 커널(필터) 크기가 작을 때]
        (장점)
        정밀한(local) 특징 추출: 작은 커널(예: 3x3)은 이미지의 세밀한 패턴, 경계, 텍스처 등 미세한 정보를 잘 포착할 수 있습니다.
        파라미터 수 감소: 작은 커널은 파라미터가 적어 모델이 가볍고, 과적합 위험도 줄어듭니다.
        계산 효율성: 연산량이 적어 빠르고, GPU 병렬 처리에 최적화되어 있습니다.
        여러 층 쌓기 용이: 작은 커널을 여러 층 쌓으면, 결과적으로 넓은 영역의 특징도 단계적으로 포착할 수 있습니다. 예를 들어, 3x3 커널 두 개를 쌓으면 5x5 커널과 비슷한 수용영역을 가질 수 있습니다.

        (단점)
        넓은 영역 포착엔 깊은 네트워크 필요: 작은 커널만 사용하면 넓은 영역의 특징을 포착하려면 레이어를 많이 쌓아야 하므로, 너무 얕은 네트워크에서는 전역적 패턴을 잘 못 볼 수 있습니다.
        정보 손실 위험: 패딩을 적절히 사용하지 않으면, 여러 번 컨볼루션을 거치며 출력 크기가 급격히 줄어들고, 정보가 손실될 수 있습니다.
    
"""
 